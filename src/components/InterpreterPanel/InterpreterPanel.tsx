import React, { useEffect, useMemo, useRef, useState } from 'react';
import { Button } from '../UI';
import { Play, Pause, Mic, Square } from 'lucide-react';
import { evaluatePronunciation, evaluateContent, combineScores } from '../../services/evalService';

interface InterpreterPanelProps {
  language: 'ko' | 'zh'; // ì›ë¬¸ ì–¸ì–´
  slide: any | null;
  slideAudioUrl?: string | null;
}

const getPrimarySecondaryNames = (lang: 'ko' | 'zh') => ({
  primary: lang === 'ko' ? 'í•œêµ­ì–´' : 'ì¤‘êµ­ì–´',
  secondary: lang === 'ko' ? 'ì¤‘êµ­ì–´' : 'í•œêµ­ì–´',
});

const InterpreterPanel: React.FC<InterpreterPanelProps> = ({ language, slide, slideAudioUrl }) => {
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const [isPlaying, setIsPlaying] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [recognizedText, setRecognizedText] = useState('');
  const recognizedStableRef = useRef<string>('');
  const [recordedChunks, setRecordedChunks] = useState<BlobPart[]>([]);
  const recChunksRef = useRef<BlobPart[]>([]);
  const [recordedBlob, setRecordedBlob] = useState<Blob | null>(null);
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null);
  const [recordedAudioUrl, setRecordedAudioUrl] = useState<string | null>(null);
  const recordedAudioRef = useRef<HTMLAudioElement | null>(null);
  const [isRecordedPlaying, setIsRecordedPlaying] = useState(false);
  const [recorderMimeType, setRecorderMimeType] = useState<string>('');
  const [isEvaluating, setIsEvaluating] = useState(false);
  const [evalResult, setEvalResult] = useState<{ overall: number; pron?: any; content?: any } | null>(null);

  const names = useMemo(() => getPrimarySecondaryNames(language), [language]);

  useEffect(() => {
    setIsPlaying(false);
    if (audioRef.current) {
      audioRef.current.pause();
      audioRef.current.currentTime = 0;
    }
  }, [slideAudioUrl, slide?.slideNumber]);

  const handlePlayPause = () => {
    if (!audioRef.current) return;
    if (isPlaying) {
      audioRef.current.pause();
      setIsPlaying(false);
    } else {
      audioRef.current.play();
      setIsPlaying(true);
    }
  };

  // ê°„ë‹¨í•œ Web Speech API ì¸ì‹ (Chrome ê³„ì—´)
  const recognitionRef = useRef<any>(null);
  useEffect(() => {
    return () => {
      if (recognitionRef.current) recognitionRef.current.stop();
    };
  }, []);

  const startRecognition = async () => {
    try { console.log('ğŸ”µ [RECORD] Starting recognition'); } catch {}
    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    if (!SpeechRecognition) {
      alert('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
      return;
    }
    // ë§ˆì´í¬ ìº¡ì²˜ ì‹œì‘(ë…¹ìŒ íŒŒì¼ í™•ë³´)
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      try { console.log('ğŸŸ¢ [RECORD] Microphone access granted'); } catch {}
      // ë¸Œë¼ìš°ì € í˜¸í™˜ ê°€ëŠ¥í•œ Opus ê¸°ë°˜ í˜•ì‹ ìš°ì„  ì„ íƒ(ogg â†’ webm)
      const preferredOgg = 'audio/ogg;codecs=opus';
      const preferredWebm = 'audio/webm;codecs=opus';
      let chosen = '';
      if ((window as any).MediaRecorder && (window as any).MediaRecorder.isTypeSupported?.(preferredOgg)) {
        chosen = preferredOgg;
      } else if ((window as any).MediaRecorder && (window as any).MediaRecorder.isTypeSupported?.(preferredWebm)) {
        chosen = preferredWebm;
      }
      const mr = new MediaRecorder(stream, chosen ? { mimeType: chosen } as MediaRecorderOptions : undefined);
      setRecorderMimeType(chosen || '');
      try { console.log('ğŸŸ¢ [RECORD] MediaRecorder created:', mr.state, { chosen }); } catch {}
      setRecordedChunks([]);
      recChunksRef.current = [];
      setRecordedBlob(null);
      recognizedStableRef.current = '';
      setRecognizedText('');
      mr.ondataavailable = (e) => {
        try { console.log('ğŸ”µ [RECORD] Data available:', e?.data?.size); } catch {}
        if (e.data && e.data.size > 0) {
          // push synchronously to ref to avoid React state timing issues
          recChunksRef.current.push(e.data);
          setRecordedChunks(prev => [...prev, e.data]);
          // Direct blob capture to avoid timing issues
          try {
            const directType = (e.data as any)?.type || chosen || 'audio/webm;codecs=opus';
            const direct = new Blob([e.data], { type: directType });
            if (direct.size > 0) setRecordedBlob(prev => (direct.size >= (prev?.size || 0) ? direct : prev));
          } catch {}
        }
      };
      mr.start();
      try { console.log('ğŸŸ¢ [RECORD] Recording started'); } catch {}
      setMediaRecorder(mr);
    } catch (e) {
      console.warn('ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨', e);
    }
    const recognition = new SpeechRecognition();
    // ì¸ì‹ ì–¸ì–´ë¥¼ ë·°ì–´ ìŠ¤í¬ë¦½íŠ¸ì˜ ë°˜ëŒ€ ì–¸ì–´ë¡œ ì„¤ì •
    recognition.lang = language === 'ko' ? 'zh-CN' : 'ko-KR';
    recognition.interimResults = true;
    recognition.continuous = true;
    recognition.onresult = (event: any) => {
      let finalSeg = '';
      let interimSeg = '';
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const seg = event.results[i][0].transcript || '';
        if (event.results[i].isFinal) finalSeg += seg; else interimSeg += seg;
      }
      if (finalSeg) recognizedStableRef.current += finalSeg;
      setRecognizedText((recognizedStableRef.current || '') + (interimSeg || ''));
    };
    recognition.onend = () => setIsRecording(false);
    recognition.onerror = () => setIsRecording(false);
    recognitionRef.current = recognition;
    recognition.start();
    setIsRecording(true);
  };

  const stopRecognition = async () => {
    try {
      console.log('ğŸ”µ [RECORD] Stopping recognition');
      console.log('ğŸ”µ [RECORD] Current chunks:', recordedChunks.length);
    } catch {}
    if (recognitionRef.current) {
      recognitionRef.current.stop();
      recognitionRef.current = null;
    }
    let audioBlob: Blob | null = null;
    if (mediaRecorder) {
      try {
        try { console.log('ğŸ”µ [RECORD] MediaRecorder state:', mediaRecorder.state); } catch {}
        await new Promise<void>((resolve) => {
          mediaRecorder.onstop = () => {
            try {
              console.log('ğŸŸ¢ [RECORD] MediaRecorder stopped');
              console.log('ğŸ”µ [RECORD] Final chunks in onstop(ref):', recChunksRef.current.length);
            } catch {}
            const fallbackType = recorderMimeType || ((recChunksRef.current[0] as any)?.type) || 'audio/webm;codecs=opus';
            try {
              const srcList = recChunksRef.current.length > 0 ? recChunksRef.current : recordedChunks;
              const blob = srcList.length > 0 ? new Blob(srcList, { type: fallbackType }) : null;
              audioBlob = blob && blob.size > 0 ? blob : (recordedBlob || null);
              if (audioBlob) { console.log('ğŸŸ¢ [RECORD] Blob ready:', { size: audioBlob.size, type: audioBlob.type }); }
              else { console.error('ğŸ”´ [RECORD] No chunks in onstop callback'); }
            } catch {}
            resolve();
          };
          mediaRecorder.stop();
        });
      } catch {}
      setMediaRecorder(null);
    }
    setRecordedBlob(audioBlob);
    try {
      if (recordedAudioUrl) {
        URL.revokeObjectURL(recordedAudioUrl);
      }
      setRecordedAudioUrl(audioBlob ? URL.createObjectURL(audioBlob) : null);
    } catch {}
    setIsRecording(false);
    // ì¸ì‹ ì¢…ë£Œ í›„ í‘œì‹œ í…ìŠ¤íŠ¸ë¥¼ ì•ˆì •í™”(ìµœì¢… í…ìŠ¤íŠ¸ ìœ ì§€)
    setRecognizedText(recognizedStableRef.current || recognizedText);
  };

  const handleEvaluate = async () => {
    try {
      setIsEvaluating(true);
      // ì°¸ì¡° ì›ë¬¸ êµ¬ì„±: ìš°ì„  í†µì—­ ëŒ€ìƒ ì–¸ì–´(ë°˜ëŒ€ ì–¸ì–´)ì˜ ìŠ¤í¬ë¦½íŠ¸, ì—†ìœ¼ë©´ í˜„ì¬ ìŠ¬ë¼ì´ë“œì˜ ì›ë¬¸ ìŠ¤í¬ë¦½íŠ¸ë¡œ í´ë°±
      const primary = language === 'ko'
        ? (slide?.koreanScript || slide?.content || '')
        : (slide?.chineseScript || slide?.content || '');
      const opposite = language === 'ko'
        ? (slide?.interpretation || '')
        : (slide?.interpretation || slide?.koreanScript || '');
      const reference = opposite || primary || '';
      try {
        console.log('ğŸ”µ Recorded blob:', recordedBlob);
        console.log('ğŸ”µ Blob size:', recordedBlob?.size);
        console.log('ğŸ”µ Blob type:', recordedBlob?.type);
      } catch {}
      const pron = await evaluatePronunciation(recordedBlob, recognizedText, reference, language === 'ko' ? 'zh' : 'ko');
      const content = await evaluateContent(recognizedText, reference, language === 'ko' ? 'zh' : 'ko');
      const overall = combineScores(pron, content);
      setEvalResult({ overall, pron, content });
    } catch (e) {
      console.warn('[Eval] failed', e);
      setEvalResult(null);
    } finally {
      setIsEvaluating(false);
    }
  };

  const handleResetRecognition = () => {
    try {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
        recognitionRef.current = null;
      }
    } catch {}
    try {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
      }
    } catch {}
    setIsRecording(false);
    setRecognizedText('');
    recognizedStableRef.current = '';
    setRecordedChunks([]);
    setRecordedBlob(null);
    try { if (recordedAudioUrl) URL.revokeObjectURL(recordedAudioUrl); } catch {}
    setRecordedAudioUrl(null);
    setIsRecordedPlaying(false);
    setEvalResult(null);
    setIsEvaluating(false);
  };

  const handleToggleRecordedPlayback = () => {
    const el = recordedAudioRef.current;
    if (!el || !recordedAudioUrl) return;
    if (isRecordedPlaying) {
      el.pause();
      setIsRecordedPlaying(false);
    } else {
      el.play();
      setIsRecordedPlaying(true);
    }
  };

  useEffect(() => {
    return () => {
      try { if (recordedAudioUrl) URL.revokeObjectURL(recordedAudioUrl); } catch {}
    };
  }, [recordedAudioUrl]);

  // ì›ë¬¸ ìŠ¤í¬ë¦½íŠ¸(ë·°ì–´ ì–¸ì–´)ì™€ í†µì—­ì•ˆ(ë°˜ëŒ€ ì–¸ì–´)ì„ ë¶„ë¦¬í•´ í‘œì‹œ
  const primaryScript: string | undefined = language === 'ko'
    ? (slide?.koreanScript || slide?.content)
    : (slide?.chineseScript || slide?.content);
  // í†µì—­ì•ˆì€ generatePPTScripts/mergePPTDataì—ì„œ í•­ìƒ slide.interpretationì— ì €ì¥ë©ë‹ˆë‹¤.
  // í•„ìš” ì‹œ ë³´ì¡°ì ìœ¼ë¡œ koreanScriptë¥¼ í´ë°±ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
  const oppositeScript: string | undefined = language === 'ko'
    ? (slide?.interpretation || '')
    : (slide?.interpretation || slide?.koreanScript || '');

  // ê°„ë‹¨ í‰ê°€ëŠ” í†µì—­ ëª©í‘œ(ë°˜ëŒ€ ì–¸ì–´) ë¬¸ì¥ê³¼ ë¹„êµ
  const expectedScript: string | undefined = oppositeScript || primaryScript;
  const keyPoints: string[] = Array.isArray(slide?.keyPoints) ? slide.keyPoints : [];

  const simpleScore = useMemo(() => {
    if (!expectedScript || !recognizedText) return 0;
    const exp = expectedScript.replace(/\s+/g, '');
    const rec = recognizedText.replace(/\s+/g, '');
    let match = 0;
    const len = Math.min(exp.length, rec.length);
    for (let i = 0; i < len; i++) if (exp[i] === rec[i]) match++;
    return Math.round((match / exp.length) * 100);
  }, [expectedScript, recognizedText]);

  const [showPrimary, setShowPrimary] = useState(true);
  const [showOpposite, setShowOpposite] = useState(true);

  return (
    <div className="flex flex-col h-full">
      <div className="p-3 border-b border-gray-200">
        <div className="flex items-center justify-between">
          <div>
            <h3 className="text-lg font-bold text-[var(--primary-brown)]">í†µì—­ ì—°ìŠµ</h3>
            <p className="text-sm text-gray-600">ì›ë¬¸: {names.primary} Â· í†µì—­: {names.secondary}</p>
          </div>
          <div className="flex items-center space-x-2"></div>
        </div>
        <audio ref={audioRef} src={slideAudioUrl || undefined} onEnded={() => setIsPlaying(false)} hidden />
      </div>
      <div className="flex-1 p-4 overflow-y-auto space-y-4">
        <div className="bg-gray-50 rounded-lg p-4">
          <div className="flex items-center justify-between mb-2" data-tour="ip-primary">
            <h4 className="font-semibold text-[var(--primary-brown)]">ìŠ¤í¬ë¦½íŠ¸ ({names.primary})</h4>
            <div className="flex items-center gap-2">
              <Button variant="outline" size="sm" onClick={() => setShowPrimary(v => !v)} aria-expanded={showPrimary}>
                {showPrimary ? 'ì ‘ê¸°' : 'í¼ì¹˜ê¸°'}
              </Button>
              <Button variant="outline" size="sm" onClick={handlePlayPause} disabled={!slideAudioUrl} title="ì›ë¬¸ ìŒì„±ì„ ì¬ìƒí•©ë‹ˆë‹¤">
                {isPlaying ? <Pause size={16} /> : <Play size={16} />}
              </Button>
            </div>
          </div>
          {showPrimary && (
            <p className="text-sm leading-relaxed whitespace-pre-wrap">{primaryScript || 'ìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.'}</p>
          )}
        </div>

        <div className="bg-[var(--background)] rounded-lg p-4">
          <div className="flex items-center justify-between mb-2" data-tour="ip-opposite">
            <h4 className="font-semibold text-[var(--primary-brown)]">í†µì—­ì•ˆ ({names.secondary})</h4>
            <div className="flex items-center gap-2">
              <Button variant="outline" size="sm" onClick={() => setShowOpposite(v => !v)} aria-expanded={showOpposite}>
                {showOpposite ? 'ì ‘ê¸°' : 'í¼ì¹˜ê¸°'}
              </Button>
              {!isRecording ? (
                <Button
                  variant="primary"
                  size="sm"
                  onClick={startRecognition}
                  data-tour="ip-record"
                  title={`ë‚˜ì˜ í†µì—­ì„ ë…¹ìŒí•©ë‹ˆë‹¤${!import.meta.env.VITE_AZURE_SPEECH_KEY ? ' (Azure í‚¤ ì—†ìŒ: ë°œìŒ í‰ê°€ëŠ” í…ìŠ¤íŠ¸ ì¶”ì •)' : ''}`}
                >
                  <Mic size={16} />
                </Button>
              ) : (
                <Button variant="outline" size="sm" onClick={stopRecognition} data-tour="ip-record" title="ë…¹ìŒì„ ì¤‘ì§€í•˜ê³  ê²°ê³¼ í™•ì¸">
                  <Square size={16} />
                </Button>
              )}
            </div>
          </div>
          {showOpposite && (
            <p className="text-sm leading-relaxed whitespace-pre-wrap">{oppositeScript || 'í†µì—­ì•ˆì´ ì—†ìŠµë‹ˆë‹¤.'}</p>
          )}
        </div>

        {keyPoints.length > 0 && (
          <div className="bg-[var(--background)] rounded-lg p-4">
            <h4 className="font-semibold text-[var(--primary-brown)] mb-2">í•µì‹¬ í¬ì¸íŠ¸</h4>
            <ul className="list-disc list-inside text-sm space-y-1">
              {keyPoints.map((k, i) => (
                <li key={i}>{k}</li>
              ))}
            </ul>
          </div>
        )}

        <div className="bg-blue-50 rounded-lg p-4">
          <div className="flex items-center justify-between mb-2">
            <h4 className="font-semibold text-blue-800">ë‚´ í†µì—­ (ë…¹ìŒ ì¸ì‹ ê²°ê³¼)</h4>
            <div className="flex items-center gap-2">
              <Button variant="outline" size="sm" onClick={handleToggleRecordedPlayback} disabled={!recordedAudioUrl} title="ë°©ê¸ˆ ë…¹ìŒí•œ ë‚´ í†µì—­ì„ ì¬ìƒí•©ë‹ˆë‹¤.">
                {isRecordedPlaying ? <Pause size={16} /> : <Play size={16} />}
              </Button>
              <Button variant="outline" size="sm" onClick={handleResetRecognition} title="ì¸ì‹ëœ í…ìŠ¤íŠ¸ì™€ ë…¹ìŒ ë°ì´í„°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.">ì´ˆê¸°í™”</Button>
              <Button variant="primary" size="sm" onClick={handleEvaluate} disabled={isRecording || (!recognizedText && !recordedBlob)} title="ë…¹ìŒ íŒŒì¼ì´ ì—†ìœ¼ë©´ ë°œìŒ í‰ê°€ëŠ” í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ê°„ëµ í‰ê°€ë©ë‹ˆë‹¤.">
                AIí‰ê°€ ìš”ì²­
              </Button>
            </div>
          </div>
          <p className="text-sm leading-relaxed text-blue-800 min-h-[48px] whitespace-pre-wrap">{recognizedText || 'ì—¬ê¸°ì— ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.'}</p>
          {/* ê°œì¸ ë…¹ìŒ ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ (ìˆ¨ê¹€) */}
          <audio ref={recordedAudioRef} src={recordedAudioUrl || undefined} hidden onEnded={() => setIsRecordedPlaying(false)} />
        </div>

        {/* í‰ê°€ ê²°ê³¼ */}
        {isEvaluating && (
          <div className="bg-yellow-50 rounded-lg p-4">
            <h4 className="font-semibold text-yellow-800 mb-1">í‰ê°€ ì¤‘...</h4>
            <p className="text-xs text-yellow-700">Azure ë°œìŒ í‰ê°€ + AI ë‚´ìš© í‰ê°€ë¥¼ ìˆ˜í–‰ ì¤‘ì…ë‹ˆë‹¤.</p>
          </div>
        )}

        {evalResult && (
          <div className="bg-white rounded-lg p-4 border">
            <h4 className="font-semibold text-gray-900 mb-3">ğŸ“Š AI í‰ê°€ ê²°ê³¼</h4>
            {/* ë°œìŒ í‰ê°€ ì‹œê°í™” */}
            {evalResult.pron && (
              <div className="mb-3">
                <div className="flex items-center justify-between mb-1">
                  <div className="font-medium text-gray-800">ğŸ¤ ë°œìŒ í‰ê°€ ({evalResult.pron.source === 'azure' ? 'Azure' : 'í…ìŠ¤íŠ¸ ì¶”ì •'})</div>
                </div>
                <div className="space-y-2">
                  {[{label:'ì •í™•ë„', value: evalResult.pron.accuracy}, {label:'ìœ ì°½ì„±', value: evalResult.pron.fluency}, {label:'ìš´ìœ¨', value: evalResult.pron.prosody ?? 0}].map((it, idx) => (
                    <div key={idx} className="text-xs text-gray-700">
                      <div className="flex items-center justify-between mb-1">
                        <span>{it.label}</span>
                        <span>{it.value}/100</span>
                      </div>
                      <div className="w-full h-2 bg-gray-100 rounded">
                        <div className={`${it.value>=80?'bg-green-500':it.value>=60?'bg-yellow-500':'bg-red-500'} h-2 rounded`} style={{ width: `${Math.max(0, Math.min(100, it.value))}%` }} />
                      </div>
                    </div>
                  ))}
                </div>
              </div>
            )}
            {/* ë‚´ìš© í‰ê°€ ì‹œê°í™” */}
            {evalResult.content && (
              <div className="mb-3">
                <div className="font-medium text-gray-800 mb-1">ğŸ“ ë‚´ìš© í‰ê°€ (AI)</div>
                <div className="space-y-2">
                  {[{label:'ì •í™•ë„', value: (evalResult.content as any).accuracy}, {label:'ì™„ì„±ë„', value: (evalResult.content as any).completeness}, {label:'ìì—°ìŠ¤ëŸ¬ì›€', value: (evalResult.content as any).fluency}].map((it, idx) => (
                    <div key={idx} className="text-xs text-gray-700">
                      <div className="flex items-center justify-between mb-1">
                        <span>{it.label}</span>
                        <span>{it.value}/100</span>
                      </div>
                      <div className="w-full h-2 bg-gray-100 rounded">
                        <div className={`${it.value>=80?'bg-green-500':it.value>=60?'bg-yellow-500':'bg-red-500'} h-2 rounded`} style={{ width: `${Math.max(0, Math.min(100, it.value))}%` }} />
                      </div>
                    </div>
                  ))}
                </div>
              </div>
            )}
            {/* ì¢…í•© ì ìˆ˜ */}
            <div className="flex items-center justify-between">
              <div className="text-sm font-semibold">ì¢…í•© ì ìˆ˜: {evalResult.overall}/100</div>
              <div className="text-xs text-gray-500">í•˜ì´ë¸Œë¦¬ë“œ(ë°œìŒ 50% + ë‚´ìš© 50%)</div>
            </div>
            {/* ìš”ì•½/ê°œì„ : ì¶•ì•½ + í† ê¸€ ìƒì„¸ */}
            {(evalResult.content?.summary || evalResult.content?.tips) && (
              <div className="mt-3">
                <div className="text-sm text-gray-800">âœ¨ ìš”ì•½: {evalResult.content?.summary}</div>
                <details className="mt-2">
                  <summary className="text-xs text-gray-600 cursor-pointer select-none">ìì„¸íˆ ë³´ê¸°</summary>
                  <div className="mt-2 space-y-1">
                    {evalResult.content?.details && evalResult.content.details.length > 0 && (
                      <ul className="list-disc list-inside text-xs text-gray-700">
                        {evalResult.content.details.map((d: string, i: number) => (
                          <li key={i}>{d}</li>
                        ))}
                      </ul>
                    )}
                    {evalResult.content?.tips && (
                      <div className="text-xs text-gray-700">ğŸ’¡ ê°œì„  ì œì•ˆ: {evalResult.content.tips}</div>
                    )}
                  </div>
                </details>
              </div>
            )}
          </div>
        )}
      </div>
    </div>
  );
};

export default InterpreterPanel;