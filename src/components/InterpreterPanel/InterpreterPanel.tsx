import React, { useEffect, useMemo, useRef, useState } from 'react';
import { Button } from '../UI';
import { Play, Pause, Mic, Square } from 'lucide-react';
import { evaluatePronunciation, evaluateContent, combineScores } from '../../services/evalService';

interface InterpreterPanelProps {
  language: 'ko' | 'zh'; // ÏõêÎ¨∏ Ïñ∏Ïñ¥
  slide: any | null;
  slideAudioUrl?: string | null;
}

const getPrimarySecondaryNames = (lang: 'ko' | 'zh') => ({
  primary: lang === 'ko' ? 'ÌïúÍµ≠Ïñ¥' : 'Ï§ëÍµ≠Ïñ¥',
  secondary: lang === 'ko' ? 'Ï§ëÍµ≠Ïñ¥' : 'ÌïúÍµ≠Ïñ¥',
});

const InterpreterPanel: React.FC<InterpreterPanelProps> = ({ language, slide, slideAudioUrl }) => {
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const [isPlaying, setIsPlaying] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [recognizedText, setRecognizedText] = useState('');
  const recognizedStableRef = useRef<string>('');
  const [recordedChunks, setRecordedChunks] = useState<BlobPart[]>([]);
  const recChunksRef = useRef<BlobPart[]>([]);
  const [recordedBlob, setRecordedBlob] = useState<Blob | null>(null);
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null);
  const [recordedAudioUrl, setRecordedAudioUrl] = useState<string | null>(null);
  const recordedAudioRef = useRef<HTMLAudioElement | null>(null);
  const [isRecordedPlaying, setIsRecordedPlaying] = useState(false);
  const [recorderMimeType, setRecorderMimeType] = useState<string>('');
  const [isEvaluating, setIsEvaluating] = useState(false);
  const [evalResult, setEvalResult] = useState<{ overall: number; pron?: any; content?: any } | null>(null);

  const names = useMemo(() => getPrimarySecondaryNames(language), [language]);

  useEffect(() => {
    setIsPlaying(false);
    if (audioRef.current) {
      audioRef.current.pause();
      audioRef.current.currentTime = 0;
    }
  }, [slideAudioUrl, slide?.slideNumber]);

  const handlePlayPause = () => {
    if (!audioRef.current) return;
    if (isPlaying) {
      audioRef.current.pause();
      setIsPlaying(false);
    } else {
      audioRef.current.play();
      setIsPlaying(true);
    }
  };

  // Í∞ÑÎã®Ìïú Web Speech API Ïù∏Ïãù (Chrome Í≥ÑÏó¥)
  const recognitionRef = useRef<any>(null);
  useEffect(() => {
    return () => {
      if (recognitionRef.current) recognitionRef.current.stop();
    };
  }, []);

  const startRecognition = async () => {
    try { console.log('üîµ [RECORD] Starting recognition'); } catch {}
    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    if (!SpeechRecognition) {
      alert('Ïù¥ Î∏åÎùºÏö∞Ï†ÄÎäî ÏùåÏÑ± Ïù∏ÏãùÏùÑ ÏßÄÏõêÌïòÏßÄ ÏïäÏäµÎãàÎã§.');
      return;
    }
    // ÎßàÏù¥ÌÅ¨ Ï∫°Ï≤ò ÏãúÏûë(ÎÖπÏùå ÌååÏùº ÌôïÎ≥¥)
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      try { console.log('üü¢ [RECORD] Microphone access granted'); } catch {}
      // Î∏åÎùºÏö∞Ï†Ä Ìò∏Ìôò Í∞ÄÎä•Ìïú Opus Í∏∞Î∞ò ÌòïÏãù Ïö∞ÏÑ† ÏÑ†ÌÉù(ogg ‚Üí webm)
      const preferredOgg = 'audio/ogg;codecs=opus';
      const preferredWebm = 'audio/webm;codecs=opus';
      let chosen = '';
      if ((window as any).MediaRecorder && (window as any).MediaRecorder.isTypeSupported?.(preferredOgg)) {
        chosen = preferredOgg;
      } else if ((window as any).MediaRecorder && (window as any).MediaRecorder.isTypeSupported?.(preferredWebm)) {
        chosen = preferredWebm;
      }
      const mr = new MediaRecorder(stream, chosen ? { mimeType: chosen } as MediaRecorderOptions : undefined);
      setRecorderMimeType(chosen || '');
      try { console.log('üü¢ [RECORD] MediaRecorder created:', mr.state, { chosen }); } catch {}
      setRecordedChunks([]);
      recChunksRef.current = [];
      setRecordedBlob(null);
      recognizedStableRef.current = '';
      setRecognizedText('');
      mr.ondataavailable = (e) => {
        try { console.log('üîµ [RECORD] Data available:', e?.data?.size); } catch {}
        if (e.data && e.data.size > 0) {
          // push synchronously to ref to avoid React state timing issues
          recChunksRef.current.push(e.data);
          setRecordedChunks(prev => [...prev, e.data]);
          // Direct blob capture to avoid timing issues
          try {
            const directType = (e.data as any)?.type || chosen || 'audio/webm;codecs=opus';
            const direct = new Blob([e.data], { type: directType });
            if (direct.size > 0) setRecordedBlob(prev => (direct.size >= (prev?.size || 0) ? direct : prev));
          } catch {}
        }
      };
      mr.start();
      try { console.log('üü¢ [RECORD] Recording started'); } catch {}
      setMediaRecorder(mr);
    } catch (e) {
      console.warn('ÎßàÏù¥ÌÅ¨ Ï†ëÍ∑º Ïã§Ìå®', e);
    }
    const recognition = new SpeechRecognition();
    // Ïù∏Ïãù Ïñ∏Ïñ¥Î•º Î∑∞Ïñ¥ Ïä§ÌÅ¨Î¶ΩÌä∏Ïùò Î∞òÎåÄ Ïñ∏Ïñ¥Î°ú ÏÑ§Ï†ï
    recognition.lang = language === 'ko' ? 'zh-CN' : 'ko-KR';
    recognition.interimResults = true;
    recognition.continuous = true;
    recognition.onresult = (event: any) => {
      let finalSeg = '';
      let interimSeg = '';
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const seg = event.results[i][0].transcript || '';
        if (event.results[i].isFinal) finalSeg += seg; else interimSeg += seg;
      }
      if (finalSeg) recognizedStableRef.current += finalSeg;
      setRecognizedText((recognizedStableRef.current || '') + (interimSeg || ''));
    };
    recognition.onend = () => setIsRecording(false);
    recognition.onerror = () => setIsRecording(false);
    recognitionRef.current = recognition;
    recognition.start();
    setIsRecording(true);
  };

  const stopRecognition = async () => {
    try {
      console.log('üîµ [RECORD] Stopping recognition');
      console.log('üîµ [RECORD] Current chunks:', recordedChunks.length);
    } catch {}
    if (recognitionRef.current) {
      recognitionRef.current.stop();
      recognitionRef.current = null;
    }
    let audioBlob: Blob | null = null;
    if (mediaRecorder) {
      try {
        try { console.log('üîµ [RECORD] MediaRecorder state:', mediaRecorder.state); } catch {}
        await new Promise<void>((resolve) => {
          mediaRecorder.onstop = () => {
            try {
              console.log('üü¢ [RECORD] MediaRecorder stopped');
              console.log('üîµ [RECORD] Final chunks in onstop(ref):', recChunksRef.current.length);
            } catch {}
            const fallbackType = recorderMimeType || ((recChunksRef.current[0] as any)?.type) || 'audio/webm;codecs=opus';
            try {
              const srcList = recChunksRef.current.length > 0 ? recChunksRef.current : recordedChunks;
              const blob = srcList.length > 0 ? new Blob(srcList, { type: fallbackType }) : null;
              audioBlob = blob && blob.size > 0 ? blob : (recordedBlob || null);
              if (audioBlob) { console.log('üü¢ [RECORD] Blob ready:', { size: audioBlob.size, type: audioBlob.type }); }
              else { console.error('üî¥ [RECORD] No chunks in onstop callback'); }
            } catch {}
            resolve();
          };
          mediaRecorder.stop();
        });
      } catch {}
      setMediaRecorder(null);
    }
    setRecordedBlob(audioBlob);
    try {
      if (recordedAudioUrl) {
        URL.revokeObjectURL(recordedAudioUrl);
      }
      setRecordedAudioUrl(audioBlob ? URL.createObjectURL(audioBlob) : null);
    } catch {}
    setIsRecording(false);
    // Ïù∏Ïãù Ï¢ÖÎ£å ÌõÑ ÌëúÏãú ÌÖçÏä§Ìä∏Î•º ÏïàÏ†ïÌôî(ÏµúÏ¢Ö ÌÖçÏä§Ìä∏ Ïú†ÏßÄ)
    setRecognizedText(recognizedStableRef.current || recognizedText);
  };

  const handleEvaluate = async () => {
    try {
      setIsEvaluating(true);
      // Ï∞∏Ï°∞ ÏõêÎ¨∏ Íµ¨ÏÑ±: Ïö∞ÏÑ† ÌÜµÏó≠ ÎåÄÏÉÅ Ïñ∏Ïñ¥(Î∞òÎåÄ Ïñ∏Ïñ¥)Ïùò Ïä§ÌÅ¨Î¶ΩÌä∏, ÏóÜÏúºÎ©¥ ÌòÑÏû¨ Ïä¨ÎùºÏù¥ÎìúÏùò ÏõêÎ¨∏ Ïä§ÌÅ¨Î¶ΩÌä∏Î°ú Ìè¥Î∞±
      const primary = language === 'ko'
        ? (slide?.koreanScript || slide?.content || '')
        : (slide?.chineseScript || slide?.content || '');
      const opposite = language === 'ko'
        ? (slide?.interpretation || '')
        : (slide?.interpretation || slide?.koreanScript || '');
      const reference = opposite || primary || '';
      try {
        console.log('üîµ Recorded blob:', recordedBlob);
        console.log('üîµ Blob size:', recordedBlob?.size);
        console.log('üîµ Blob type:', recordedBlob?.type);
      } catch {}
      const pron = await evaluatePronunciation(recordedBlob, recognizedText, reference, language === 'ko' ? 'zh' : 'ko');
      const content = await evaluateContent(recognizedText, reference, language === 'ko' ? 'zh' : 'ko');
      const overall = combineScores(pron, content);
      setEvalResult({ overall, pron, content });
    } catch (e) {
      console.warn('[Eval] failed', e);
      setEvalResult(null);
    } finally {
      setIsEvaluating(false);
    }
  };

  const handleResetRecognition = () => {
    try {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
        recognitionRef.current = null;
      }
    } catch {}
    try {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
      }
    } catch {}
    setIsRecording(false);
    setRecognizedText('');
    recognizedStableRef.current = '';
    setRecordedChunks([]);
    setRecordedBlob(null);
    try { if (recordedAudioUrl) URL.revokeObjectURL(recordedAudioUrl); } catch {}
    setRecordedAudioUrl(null);
    setIsRecordedPlaying(false);
    setEvalResult(null);
    setIsEvaluating(false);
  };

  const handleToggleRecordedPlayback = () => {
    const el = recordedAudioRef.current;
    if (!el || !recordedAudioUrl) return;
    if (isRecordedPlaying) {
      el.pause();
      setIsRecordedPlaying(false);
    } else {
      el.play();
      setIsRecordedPlaying(true);
    }
  };

  useEffect(() => {
    return () => {
      try { if (recordedAudioUrl) URL.revokeObjectURL(recordedAudioUrl); } catch {}
    };
  }, [recordedAudioUrl]);

  // ÏõêÎ¨∏ Ïä§ÌÅ¨Î¶ΩÌä∏(Î∑∞Ïñ¥ Ïñ∏Ïñ¥)ÏôÄ ÌÜµÏó≠Ïïà(Î∞òÎåÄ Ïñ∏Ïñ¥)ÏùÑ Î∂ÑÎ¶¨Ìï¥ ÌëúÏãú
  const primaryScript: string | undefined = language === 'ko'
    ? (slide?.koreanScript || slide?.content)
    : (slide?.chineseScript || slide?.content);
  // ÌÜµÏó≠ÏïàÏùÄ generatePPTScripts/mergePPTDataÏóêÏÑú Ìï≠ÏÉÅ slide.interpretationÏóê Ï†ÄÏû•Îê©ÎãàÎã§.
  // ÌïÑÏöî Ïãú Î≥¥Ï°∞Ï†ÅÏúºÎ°ú koreanScriptÎ•º Ìè¥Î∞±ÏúºÎ°ú ÏÇ¨Ïö©Ìï©ÎãàÎã§.
  const oppositeScript: string | undefined = language === 'ko'
    ? (slide?.interpretation || '')
    : (slide?.interpretation || slide?.koreanScript || '');

  // Í∞ÑÎã® ÌèâÍ∞ÄÎäî ÌÜµÏó≠ Î™©Ìëú(Î∞òÎåÄ Ïñ∏Ïñ¥) Î¨∏Ïû•Í≥º ÎπÑÍµê
  const expectedScript: string | undefined = oppositeScript || primaryScript;
  const keyPoints: string[] = Array.isArray(slide?.keyPoints) ? slide.keyPoints : [];

  const simpleScore = useMemo(() => {
    if (!expectedScript || !recognizedText) return 0;
    const exp = expectedScript.replace(/\s+/g, '');
    const rec = recognizedText.replace(/\s+/g, '');
    let match = 0;
    const len = Math.min(exp.length, rec.length);
    for (let i = 0; i < len; i++) if (exp[i] === rec[i]) match++;
    return Math.round((match / exp.length) * 100);
  }, [expectedScript, recognizedText]);

  const [showPrimary, setShowPrimary] = useState(true);
  const [showOpposite, setShowOpposite] = useState(true);

  return (
    <div className="flex flex-col h-full">
      <div className="p-3 border-b border-gray-200">
        <div className="flex items-center justify-between">
          <div>
            <h3 className="text-lg font-bold text-[var(--primary-brown)]">ÌÜµÏó≠ Ïó∞Ïäµ</h3>
            <p className="text-sm text-gray-600">ÏõêÎ¨∏: {names.primary} ¬∑ ÌÜµÏó≠: {names.secondary}</p>
          </div>
          <div className="flex items-center space-x-2"></div>
        </div>
        <audio ref={audioRef} src={slideAudioUrl || undefined} onEnded={() => setIsPlaying(false)} hidden />
      </div>
      <div className="flex-1 p-4 overflow-y-auto space-y-4">
        <div className="bg-gray-50 rounded-lg p-4">
          <div className="flex items-center justify-between mb-2" data-tour="ip-primary">
            <h4 className="font-semibold text-[var(--primary-brown)]">Ïä§ÌÅ¨Î¶ΩÌä∏ ({names.primary})</h4>
            <div className="flex items-center gap-2">
              <Button variant="outline" size="sm" onClick={() => setShowPrimary(v => !v)} aria-expanded={showPrimary}>
                {showPrimary ? 'Ï†ëÍ∏∞' : 'ÌéºÏπòÍ∏∞'}
              </Button>
              <Button variant="outline" size="sm" onClick={handlePlayPause} disabled={!slideAudioUrl} title="ÏõêÎ¨∏ ÏùåÏÑ±ÏùÑ Ïû¨ÏÉùÌï©ÎãàÎã§">
                {isPlaying ? <Pause size={16} /> : <Play size={16} />}
              </Button>
            </div>
          </div>
          {showPrimary && (
            <p className="text-sm leading-relaxed whitespace-pre-wrap">{primaryScript || 'Ïä§ÌÅ¨Î¶ΩÌä∏Í∞Ä ÏóÜÏäµÎãàÎã§.'}</p>
          )}
        </div>

        <div className="bg-[var(--background)] rounded-lg p-4">
          <div className="flex items-center justify-between mb-2" data-tour="ip-opposite">
            <h4 className="font-semibold text-[var(--primary-brown)]">ÌÜµÏó≠Ïïà ({names.secondary})</h4>
            <div className="flex items-center gap-2">
              <Button variant="outline" size="sm" onClick={() => setShowOpposite(v => !v)} aria-expanded={showOpposite}>
                {showOpposite ? 'Ï†ëÍ∏∞' : 'ÌéºÏπòÍ∏∞'}
              </Button>
              {!isRecording ? (
                <Button
                  variant="primary"
                  size="sm"
                  onClick={startRecognition}
                  data-tour="ip-record"
                  title={`ÎÇòÏùò ÌÜµÏó≠ÏùÑ ÎÖπÏùåÌï©ÎãàÎã§${!import.meta.env.VITE_AZURE_SPEECH_KEY ? ' (Azure ÌÇ§ ÏóÜÏùå: Î∞úÏùå ÌèâÍ∞ÄÎäî ÌÖçÏä§Ìä∏ Ï∂îÏ†ï)' : ''}`}
                >
                  <Mic size={16} />
                </Button>
              ) : (
                <Button variant="outline" size="sm" onClick={stopRecognition} data-tour="ip-record" title="ÎÖπÏùåÏùÑ Ï§ëÏßÄÌïòÍ≥† Í≤∞Í≥º ÌôïÏù∏">
                  <Square size={16} />
                </Button>
              )}
            </div>
          </div>
          {showOpposite && (
            <p className="text-sm leading-relaxed whitespace-pre-wrap">{oppositeScript || 'ÌÜµÏó≠ÏïàÏù¥ ÏóÜÏäµÎãàÎã§.'}</p>
          )}
        </div>

        {keyPoints.length > 0 && (
          <div className="bg-[var(--background)] rounded-lg p-4">
            <h4 className="font-semibold text-[var(--primary-brown)] mb-2">ÌïµÏã¨ Ìè¨Ïù∏Ìä∏</h4>
            <ul className="list-disc list-inside text-sm space-y-1">
              {keyPoints.map((k, i) => (
                <li key={i}>{k}</li>
              ))}
            </ul>
          </div>
        )}

        <div className="bg-blue-50 rounded-lg p-4">
          <div className="flex items-center justify-between mb-2">
            <h4 className="font-semibold text-blue-800">ÎÇ¥ ÌÜµÏó≠ (ÎÖπÏùå Ïù∏Ïãù Í≤∞Í≥º)</h4>
            <div className="flex items-center gap-2">
              <Button variant="outline" size="sm" onClick={handleToggleRecordedPlayback} disabled={!recordedAudioUrl} title="Î∞©Í∏à ÎÖπÏùåÌïú ÎÇ¥ ÌÜµÏó≠ÏùÑ Ïû¨ÏÉùÌï©ÎãàÎã§.">
                {isRecordedPlaying ? <Pause size={16} /> : <Play size={16} />}
              </Button>
              <Button variant="outline" size="sm" onClick={handleResetRecognition} title="Ïù∏ÏãùÎêú ÌÖçÏä§Ìä∏ÏôÄ ÎÖπÏùå Îç∞Ïù¥ÌÑ∞Î•º Ï¥àÍ∏∞ÌôîÌï©ÎãàÎã§.">Ï¥àÍ∏∞Ìôî</Button>
              <Button variant="primary" size="sm" onClick={handleEvaluate} disabled={isRecording || (!recognizedText && !recordedBlob)} title="ÎÖπÏùå ÌååÏùºÏù¥ ÏóÜÏúºÎ©¥ Î∞úÏùå ÌèâÍ∞ÄÎäî ÌÖçÏä§Ìä∏ Í∏∞Î∞òÏúºÎ°ú Í∞ÑÎûµ ÌèâÍ∞ÄÎê©ÎãàÎã§.">
                AIÌèâÍ∞Ä ÏöîÏ≤≠
              </Button>
            </div>
          </div>
          <p className="text-sm leading-relaxed text-blue-800 min-h-[48px] whitespace-pre-wrap">{recognizedText || 'Ïó¨Í∏∞Ïóê ÏùåÏÑ± Ïù∏Ïãù Í≤∞Í≥ºÍ∞Ä ÌëúÏãúÎê©ÎãàÎã§.'}</p>
          {/* Í∞úÏù∏ ÎÖπÏùå Ïò§ÎîîÏò§ ÌîåÎ†àÏù¥Ïñ¥ (Ïà®ÍπÄ) */}
          <audio ref={recordedAudioRef} src={recordedAudioUrl || undefined} hidden onEnded={() => setIsRecordedPlaying(false)} />
        </div>

        {/* ÌèâÍ∞Ä Í≤∞Í≥º */}
        {isEvaluating && (
          <div className="bg-yellow-50 rounded-lg p-4">
            <h4 className="font-semibold text-yellow-800 mb-1">ÌèâÍ∞Ä Ï§ë...</h4>
            <p className="text-xs text-yellow-700">Azure Î∞úÏùå ÌèâÍ∞Ä + AI ÎÇ¥Ïö© ÌèâÍ∞ÄÎ•º ÏàòÌñâ Ï§ëÏûÖÎãàÎã§.</p>
          </div>
        )}

        {evalResult && (
          <div className="bg-white rounded-lg p-4 border">
            <h4 className="font-semibold text-gray-900 mb-3">üìä AI ÌèâÍ∞Ä Í≤∞Í≥º</h4>
            {/* Î∞úÏùå ÌèâÍ∞Ä ÏãúÍ∞ÅÌôî */}
            {evalResult.pron && (
              <div className="mb-3">
                <div className="flex items-center justify-between mb-1">
                  <div className="font-medium text-gray-800">üé§ Î∞úÏùå ÌèâÍ∞Ä ({evalResult.pron.source === 'azure' ? 'Azure' : 'ÌÖçÏä§Ìä∏ Ï∂îÏ†ï'})</div>
                </div>
                <div className="space-y-2">
                  {[{label:'Ï†ïÌôïÎèÑ', value: evalResult.pron.accuracy}, {label:'Ïú†Ï∞ΩÏÑ±', value: evalResult.pron.fluency}, {label:'Ïö¥Ïú®', value: evalResult.pron.prosody ?? 0}].map((it, idx) => (
                    <div key={idx} className="text-xs text-gray-700">
                      <div className="flex items-center justify-between mb-1">
                        <span>{it.label}</span>
                        <span>{it.value}/100</span>
                      </div>
                      <div className="w-full h-2 bg-gray-100 rounded">
                        <div className={`${it.value>=80?'bg-green-500':it.value>=60?'bg-yellow-500':'bg-red-500'} h-2 rounded`} style={{ width: `${Math.max(0, Math.min(100, it.value))}%` }} />
                      </div>
                    </div>
                  ))}
                </div>
              </div>
            )}
            {/* ÎÇ¥Ïö© ÌèâÍ∞Ä ÏãúÍ∞ÅÌôî */}
            {evalResult.content && (
              <div className="mb-3">
                <div className="font-medium text-gray-800 mb-1">üìù ÎÇ¥Ïö© ÌèâÍ∞Ä (AI)</div>
                <div className="space-y-2">
                  {[{label:'Ï†ïÌôïÎèÑ', value: (evalResult.content as any).accuracy}, {label:'ÏôÑÏÑ±ÎèÑ', value: (evalResult.content as any).completeness}, {label:'ÏûêÏó∞Ïä§Îü¨ÏõÄ', value: (evalResult.content as any).fluency}].map((it, idx) => (
                    <div key={idx} className="text-xs text-gray-700">
                      <div className="flex items-center justify-between mb-1">
                        <span>{it.label}</span>
                        <span>{it.value}/100</span>
                      </div>
                      <div className="w-full h-2 bg-gray-100 rounded">
                        <div className={`${it.value>=80?'bg-green-500':it.value>=60?'bg-yellow-500':'bg-red-500'} h-2 rounded`} style={{ width: `${Math.max(0, Math.min(100, it.value))}%` }} />
                      </div>
                    </div>
                  ))}
                </div>
              </div>
            )}
            {/* Ï¢ÖÌï© Ï†êÏàò */}
            <div className="flex items-center justify-between">
              <div className="text-sm font-semibold">Ï¢ÖÌï© Ï†êÏàò: {evalResult.overall}/100</div>
              <div className="text-xs text-gray-500">ÌïòÏù¥Î∏åÎ¶¨Îìú(Î∞úÏùå 50% + ÎÇ¥Ïö© 50%)</div>
            </div>
            {/* ÏöîÏïΩ/Í∞úÏÑ†: Ï∂ïÏïΩ + ÌÜ†Í∏Ä ÏÉÅÏÑ∏ */}
            {(evalResult.content?.summary || evalResult.content?.tips) && (
              <div className="mt-3">
                <div className="text-sm text-gray-800">‚ú® ÏöîÏïΩ: {evalResult.content?.summary}</div>
                <details className="mt-2">
                  <summary className="text-xs text-gray-600 cursor-pointer select-none">ÏûêÏÑ∏Ìûà Î≥¥Í∏∞</summary>
                  <div className="mt-2 space-y-1">
                    {evalResult.content?.details && evalResult.content.details.length > 0 && (
                      <ul className="list-disc list-inside text-xs text-gray-700">
                        {evalResult.content.details.map((d: string, i: number) => (
                          <li key={i}>{d}</li>
                        ))}
                      </ul>
                    )}
                    {evalResult.content?.tips && (
                      <div className="text-xs text-gray-700">üí° Í∞úÏÑ† Ï†úÏïà: {evalResult.content.tips}</div>
                    )}
                  </div>
                </details>
              </div>
            )}
          </div>
        )}
      </div>
    </div>
  );
};

export default InterpreterPanel;